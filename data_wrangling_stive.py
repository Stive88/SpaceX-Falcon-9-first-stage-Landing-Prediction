# -*- coding: utf-8 -*-
"""data_wrangling.stive.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SXKscVlgi6g2EIRMj3pBOduJoNv2vDjF

# #   Data wrangling
We will import the following libraries.
Data wrangling is the process of converting and cleaning raw data into a suitable format for data analysis. It's like taking messy, unorganized data and turning it into something neat and tidy that can be easily understood and used. Think of it as preparing a meal; you need to gather the ingredients, clean them, and cut them into the right sizes before you can cook a delicious dish.
Key steps in data wrangling include:
Cleaning data
Transforming data
Combining data
Structuring data
-----------------------------------
Why is data wrangling important?
Accuracy: Clean and organized data leads to more accurate and reliable results.
Efficiency: Well-prepared data can save time and effort in the analysis process.
Insights: Data wrangling helps uncover patterns and insights that might otherwise be hidden.
-----------------------------------
#Wrangling significa pulire e preparare dati grezzi e disomogenei raccolti da diverse fonti. Questi dati potrebbero essere incompleti, duplicati o in formati diversi.
"""

## Pandas is a software library written for the Python programming language for data manipulation and analysis.
import pandas as pd

#NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays
import numpy as np

df = pd.read_csv("https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_2.csv")

df.head(5)

df.info()

df.isnull().sum()

#"which I previously got through API and cleaned and saved in my computer"
#import os

#os.getcwd()

#df= pd.read_csv('dataset_falcon9.csv')

#Identify and calculate the percentage of the missing values in each attribute
df.isnull().sum()/df.shape[0]*100

df.dtypes

df.describe()

"""# # TASK 1: Calculate the number of launches on each site
The data contains several Space X launch facilities: Cape Canaveral Space Launch Complex 40 VAFB SLC 4E , Vandenberg Air Force Base Space Launch Complex 4E (SLC-4E), Kennedy Space Center Launch Complex 39A KSC LC 39A .The location of each Launch Is placed in the column LaunchSite

Next, let's see the number of launches for each site.

Use the method value_counts() on the column LaunchSite to determine the number of launches on each site:
"""

df.info()

# Apply value_counts() on column LaunchSite
df['LaunchSite'].value_counts()

df['Longitude'].value_counts()

"""# # TASK 2: Calculate the number and occurrence of each orbit"""

# Apply value_counts on Orbit column
df['Orbit'].value_counts()

"""# # TASK 3: Calculate the number and occurence of mission outcome per orbit type
Use the method .value_counts() on the column Outcome to determine the number of landing_outcomes.Then assign it to a variable landing_outcomes.
"""

# landing_outcomes = values on Outcome column
landing_outcomes= df['Outcome'].value_counts()
landing_outcomes

"""True Ocean means the mission outcome was successfully landed to a specific region of the ocean while False Ocean means the mission outcome was unsuccessfully landed to a specific region of the ocean. True RTLS means the mission outcome was successfully landed to a ground pad False RTLS means the mission outcome was unsuccessfully landed to a ground pad.True ASDS means the mission outcome was successfully landed to a drone ship False ASDS means the mission outcome was unsuccessfully landed to a drone ship. None ASDS and None None these represent a failure to land."""

enumerate(landing_outcomes.keys())

for i,outcome in enumerate(landing_outcomes.keys()):
    print(i,outcome)

#"This means that any landing that results in a 'bad_outcome' is considered a failure. The values 'nan_nan' are indexed as the first element and a set is created from them. These are then called and the 'nan' and 'false' values are considered as part of the 'bad_outcome' result."
bad_outcomes=set(landing_outcomes.keys()[[1,3,5,6,7]])
bad_outcomes

df_success = df[df["Class"]==1]
df_fai = df[df["Class"] !=1]

print(df_success['Outcome'].value_counts())

print(df_fai['Outcome'].value_counts())

"""# TASK 4: Create a landing outcome label from Outcome column
Using the Outcome, create a list where the element is zero if the corresponding row in Outcome is in the set bad_outcome; otherwise, it's one. Then assign it to the variable landing_class:

This variable will represent the classification variable that represents the outcome of each launch. If the value is zero, the first stage did not land successfully; one means the first stage landed Successfully
"""

# landing_class = 0 if bad_outcome
# landing_class = 1 otherwise
outcome
bad_outcomes=['False ASDS', 'False Ocean', 'False RTLS', 'None ASDS', 'None None']
landing_class=[]
for i in df['Outcome']:
    if i in bad_outcomes:
        landing_class.append(0)
    else:
        landing_class.append(1)

print(landing_class)

df['Class']=landing_class
df[['Class']].head(10)

df.head(5)

"""We can use the following line of code to determine the success rate:"""

df["Class"].mean()

"""We can now export it to a CSV for the next section,but to make the answers consistent, in the next lab we will provide data in a pre-selected date range."""

df.to_csv("dataset_part_2.csv", index=False)